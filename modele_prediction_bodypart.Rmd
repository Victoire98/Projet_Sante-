---
title: "R Notebook"
output: html_notebook
---

**Note** : 

#### Dans la base de données originale, il n'y a que 31 diagnostics reconnus, ce n'est pas une bonne idée de les laisser dans une seule colonne. Cela génère plus de 15 000 diagnostics 
```{r}
library("dplyr")
#date
library("lubridate")
#data manipulation,
library(tidyr)
library(ggplot2)
library(doParallel)
library(randomForest)

```

```{r}
#change in diagnostic
path = "~/Documents/3eme-annee/Data R/Projet_Sante-/"
setwd(path)
load("dataset.Rdata")
#-----new dataset to make the model
## ------Onehot Encoding to factor

```
```{r}
data.model <- data
data.model$output <- (substring(names(data[,5:30]),first = 11)[max.col(data[,5:30])])
data.model[,5:30] <- NULL
data.model$output <- as.factor(data.model$output)
#put the original vector
print(str(data.model$diag))
names(data.model)[1] <- "date"
```

1. description du dataset 
```{r}
data.model <- subset(data.model, select=c(date,age:output))
levels(data.model$output)[1] <- levels(data.model$output)[2]
str(data.model)

##### save
save(data.model,file="dataset_model.Rdata")
```

# Premier approach

---------------------------------
summary

# ------ modele un jour


## correlation categorical

**Pearson's chi-squared test (χ2)**  is a statistical test applied to sets of categorical data to evaluate how likely it is that any observed difference between the sets arose by chance. It is the most widely used of many chi-squared tests (e.g., Yates, likelihood ratio, portmanteau test in time series, etc.)

 > The measure of association does not indicate causality, but association–that is, whether a variable is associated with another variable. This measure of association also indicates the strength of the relationship, whether, weak or strong.
 Since,nominal categorical predictor’s, the Goodman and Kruskal’s tau measure is appropriate. Interested readers are invited to see pages 68 and 69 of the Agresti book. More information on this test can be seen here
 
[link](https://www.r-bloggers.com/to-eat-or-not-to-eat-thats-the-question-measuring-the-association-between-categorical-variables/)
```{r}
load("dataset_model_full.Rdata")
library(GoodmanKruskal)
#categorical data 

varset1 <- names(Filter(is.factor,data.full))
varset1

dataFrame1<- subset(data.full, select = varset1)
#make matrix
GKmatrix1<- GKtauDataframe(dataFrame1)
plot(GKmatrix1, corrColors = "blue")
```
> The off-diagonal elements contain the forward and backward tau measures for each variable pair. Specifically, the numerical values appearing in each row represent the association measure τ(x,y)τ(x,y) from the variable xx indicated in the row name to the variable yy indicated in the column name.

> The most obvious feature from this plot is the fact that the variable odor is almost perfectly predictable (i.e. τ(x,y)=0.94) from class and this forward association is quite strong. The forward association suggest that x=odor (which has levels “almond”, “creosote”, “foul”, “anise”, “musty”, “nosmell”, “pungent”, “spicy”, “fishy”) is highly predictive of y=class (which has levels “edible”, “poisonous”). 

> x=cap shape is weakly associated to y=cap surface (i.e.τ(x,y)=0.03) and (i.e.τ(y,x)=0.01). Thus, we can safely say that although these two variables are significant but they are association is weak; i.e. it will be difficult to predict one from another.


```{r}

#model
table(data.model$output)
```
1. tomar la misma cantidad por cada clase
2. nnet


```{r}

levels(data.model$output)[1] <- levels(data.model$output)[2]  # remove "25% body" factor, it becomes all body
table(data.model$output)

#create a dataset with 5000 samples by factor
sel <- subset(data.model, data.model$output == levels(data.model$output)[1]) #get obs from all body
data.good <- sel[sample(1:nrow(sel),5000),]

#get from the others
for(l in levels(data.model$output)[-1]){
  sel <- subset(data.model, data.model$output == l)
  data.good <- rbind(data.good, sel[sample(1:nrow(sel),5000),])
}
### new dataset
str(data.good)
head(data.good)
save(data.good,file ="dataset_balanced.Rdata")



```

### function to plot the confusion matrix

```{r}
plot_confusion_matrix <- function(out.pred,true.label,title){
                        mat <- as.data.frame(prop.table(table(out.pred,true.label),1)) #normalize by class
                        plot <- ggplot(mat,aes(x = out.pred,y=true.label,fill=Freq))+
                                geom_tile()+
                                ggtitle(title)+
                                theme(axis.text.x = element_text(angle=45, hjust = 1))+ #incline text
                                xlab("true.label")+
                                xlab("predicted")
                        return(plot)
}
```


## model output

```{r}
load("dataset_balanced.Rdata")


#split
dataset <- data.good[,c("date","age","diag","prod1","output")]
dataset <- dataset[sample(1:nrow(dataset),nrow(dataset)),] #permute dataset

#only the 52 products most populars
prod.plus <- as.data.frame(sort(table(dataset$prod1),decreasing = TRUE))[1:52,1]
levels(dataset$prod1)[!levels(dataset$prod1) %in% prod.plus] <- "XX"
print(str(dataset))
#model
plot(table(dataset$output))

test_size <- round(0.7 * nrow(dataset))
train_data1 = dataset[1:test_size,]
test_data1 = dataset[-(1:test_size),]



set.seed(12345)
model.grf <- randomForest( output ~. , data = train_data1, ntree = 100)
print(model.grf)
varImpPlot(model.grf)

out.pred1 <- predict(model.grf, train_data1[,-5]) #all data, mtry auto, 100nt
out.pred1.t <- predict(model.grf, test_data1[,-5]) #all data, mtry auto, 100nt

```
#model numerique
```{r}
dataset <- data.good[,c("date","age","diag","prod1","output")]
dataset <- dataset[sample(1:nrow(dataset),nrow(dataset)),] #permute dataset

dataset$diag <-as.numeric(dataset$diag)
dataset$prod1 <-as.numeric(dataset$prod1)

test_size <- round(0.7 * nrow(dataset))
train_data2 = dataset[1:test_size,]
test_data2 = dataset[-(1:test_size),]

set.seed(12345)
model.num <- randomForest( output ~. , data = train_data2, ntree = 100)
print(model.num)
varImpPlot(model.num)

out.pred2 <- predict(model.num, train_data2[,-5]) #all data, mtry auto, 100nt
out.pred2.t <- predict(model.num, test_data2[,-5]) #all data, mtry auto, 100nt

```



#model numerique aleatoire
```{r}
load("dataset_model.Rdata")
dataset <- data.model[,c("date","age","diag","prod1","output")]
dataset <- dataset[sample(1:nrow(dataset),125000),] #permute dataset
print(table(dataset$output))
dataset$diag <-as.numeric(dataset$diag)
dataset$prod1 <-as.numeric(dataset$prod1)

test_size <- round(0.7 * nrow(dataset))
train_data3 = dataset[1:test_size,]
test_data3 = dataset[-(1:test_size),]

set.seed(12345)
model.num.al <- randomForest( output ~. , data = train_data3, ntree = 100)
print(model.num.al)
varImpPlot(model.num.al)

out.pred3 <- predict(model.num.al, train_data3[,-5]) #all data, mtry auto, 100nt
out.pred3.t <- predict(model.num.al, test_data3[,-5]) #all data, mtry auto, 100nt

```
##results

```{r}
p1 <- plot_confusion_matrix(out.pred1,train_data1$output,"CM of output (training_data) m1")
p2 <- plot_confusion_matrix(out.pred2,train_data2$output,"CM of output (training_data) m2")
p3 <- plot_confusion_matrix(out.pred3,train_data3$output,"CM of output (training_data) m3")
##test
p1.t <- plot_confusion_matrix(out.pred1.t,test_data1$output,"CM of output (test_data) m1")
p2.t <- plot_confusion_matrix(out.pred2.t,test_data2$output,"CM of output (test_data) m2")
p3.t <- plot_confusion_matrix(out.pred3.t,test_data3$output,"CM of output (test_data) m3")

library(cowplot)
figure1 <- plot_grid(p1,p2,p3,
                    ncol = 3, nrow = 1,
                    align = "hv")
figure1
figure2 <- plot_grid(p1.t,p2.t,p3.t,
                    ncol = 3, nrow = 1,
                    align = "hv")
figure2

save_plot("cm_rf_output.png", figure1, ncol = 3, nrow = 2)
```

```{r}
res <- data.frame(classes = model.grf$classes,
    err1 = model.grf$confusion[,26], 
    err2= model.num$confusion[,26],
    err3= model.num.al$confusion[,26])
colors <- c("M1:balanced.factor" = "gray", "M2:balanced.num" = "orange", "M3:random.num" = "red")
ggplot(res, aes(x=classes))+
  geom_bar(stat="identity",aes(y=err2), color= colors[1])+
  geom_point(aes(y=err2), color= colors[2])+
  geom_point(aes(y=err3), color= colors[3])+
  labs(fill='NEW LEGEND TITLE')+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  ylab("Class Error")
```